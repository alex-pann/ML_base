{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7788607",
   "metadata": {},
   "source": [
    "## Вероятностные основы модели линейной регрессии\n",
    "Панасик Александра, Б03-004\n",
    "\n",
    "**Постановка задачи и формулировка предположений** <br />\n",
    "Сформулируем задачу регрессии и введем некоторые обозначения. <br />\n",
    "Имеется выборка $ \\tau: \\{\\vec x_i, y_i\\} $ из N объектов (результатов измерений). Индекс i везде будет указываеть на порядковый номер объекта, $ i \\in \\{1, N\\}$.  <br /> \n",
    "$ x_i \\in X $ -  множество признаков объектов, $ \\vec x_i $ - признаковое описание i-ого объекта, вектор действительных чисел. <br />\n",
    "$ y_i \\in Y $ - множество ответов (целевой переменной), действительные числа. <br />\n",
    "Задача - найти зависимость между признакакми объекта и целевой переменной: $ F : X \\rightarrow Y$ - искомая закономерность.  <br />\n",
    "\n",
    "Для решения поставленной задачи сделаем несколько предположений относительно характера искомой зависимости и целевой переменной. Предположим, что в обучающей выборке каждому $x_i$ соответствует множество независимых одинаково распределенных случайных величин $y_i$, т.е. мы считаем, что целевая переменная порождается из некоторого вероятностного распределения, причем параметры этого распределения одинаковы для всех объектов. Пусть это распределение - распределение Лапласа с плотностью вероятности $\\rho(\\mu, b) = \\frac{1}{2b} e^{-\\frac{|y_i-\\mu|}{b}}$, где $\\mu$ - среднее значение (матожидание), $b$ -  разброс значений.\n",
    "Также предполагается, что связь между признаками объекта $x_i$ и соответсвтующей целевой переменной $y_i$ имеет линейный характер. Таким образом, задача сводится к нахождению параметров распределения целевой переменной. <br />\n",
    "\n",
    "Итак, при решении поставленной задачи мы используем следующие 4 предположения: <br />\n",
    "- **Linear:** предполагаем, что целевая переменная линейно зависит от признаков объекта: $ \\mu_i = \\theta^T \\cdot \\vec x_i $. Здесь $\\mu_i$  -  ответ модели, значение целевой переменной для i-ого объекта (т.е. среднее значение распределения $y_i$), $\\vec x_i$ - признаки i-ого объекта, $\\theta$ - вектор параметров модели;\n",
    "- **Independent identical distributed:** предполагаем, что объекты независимы и однаково распределены, т.е. порождены одним процессом;\n",
    "- **Распределение:** считаем, что целевая переменная порождается из распределения Лапласа: $ y \\sim \\frac{1}{2b} exp(-\\frac{|y_i-\\mu|}{b})$;\n",
    "- **Equivalence:** разброс целевой переменной одинаков для всех объектов выборки: $b_i ^2 = b^2 $;\n",
    "\n",
    "**Метод максимизации правдоподобия** <br />\n",
    "Для решения поставленной задачи используем метод максимизации правдоподобия. <br />\n",
    "Правдоподобие i-ого объекта обучающей выборки $P(x_i, y_i, \\theta)$ - это вероятность получить для объекта с признаками $\\vec x_i$ ответ $y_i$ при заданных параметрах модели $\\theta$. Поскольку $y_i$, согласно нашим предположениям, имеет распределение Лапласа, то:\n",
    "$$\n",
    "P(x_i, y_i, \\theta) = \\frac{1}{2b} exp(-\\frac{|y_i-\\mu_i|}{b}),\n",
    "$$\n",
    "где $\\mu_i = \\theta^T \\cdot \\vec x_i$ - ответ модели.\n",
    "\n",
    "Правдоподобие всей обучающей выборки $L(\\tau, \\theta)$, или $P(\\tau|\\theta)$ - это вероятность получить выборку $\\tau$ при заданных параметрах $\\theta$. Поскольку все объекты независимы, вероятность для выборки целиком равна произведению вероятностей для каждого объекта:\n",
    "$$\n",
    "L(\\tau, \\theta) = P(\\tau|\\theta) = \\prod_{i=1}^{N} \\frac{1}{2b} exp(-\\frac{|y_i-\\theta^T  \\vec x_i|}{b})\n",
    "$$\n",
    "Для решения задачи линейной регрессии нужно подобрать такие параметры модели $\\theta$, чтобы ответ модели $\\mu_i = \\theta^T \\vec x_i$ на обучающей выборке был как можно ближе к референтному (измеренному) значению $y_i$. Другими словами, нужно за счет $\\theta$ максимизировать значение правдоподобия выборки. Решением является значение параметров модели $\\theta^*$, при котором достигается максимальное значение правдоподобия выборки:\n",
    "$$ \n",
    "\\theta^* = \\underset{\\theta}{\\operatorname{argmax}} \\left[L(\\tau, \\theta)\\right]  = \\underset{\\theta}{\\operatorname{argmax}} \\left[ln (L(\\tau, \\theta))\\right]\n",
    "$$\n",
    "Последнее равенство верно, так как функция логарифма строго возрастает и потому не меняет положение максимума.\n",
    "Далее, поскольку логарифм произведения равен сумме логарифмов, получаем:\n",
    "$$\n",
    "ln(L(\\tau, \\theta)) = ln \\left( \\prod_{i=1}^{N} \\frac{1}{2b} e^{-\\frac{|y_i-\\theta^T \\vec x_i|}{b}}\\right) = \\sum_{i = 1}^{N} ln \\left(\\frac{1}{2b} e^{-\\frac{|y_i-\\theta^T \\vec x_i|}{b}}\\right) = \\sum_{i = 1}^{N} \\left[ ln(1/2b) -\\frac{|y_i-\\theta^T \\vec x_i|}{b} \\right]\n",
    "$$\n",
    "Разброс $b$ одинаков для всех N объектов, поэтому:\n",
    "$$\n",
    "ln(L(\\tau, \\theta)) = N \\cdot ln(1/2b) - \\sum_{i = 1}^{N} \\left[ \\frac{|y_i-\\theta^T \\vec x_i|}{b} \\right]\n",
    "$$\n",
    "При максимизации полученного значения по параметру $\\theta$ первое слагаемое и знаменатель второго слагаемого - константы, не зависящие от параметра. Поэтому искомое значение\n",
    "$$\n",
    "\\theta^* =  \\underset{\\theta}{\\operatorname{argmax}} \\left[ln (L(\\tau, \\theta))\\right] = \\underset{\\theta}{\\operatorname{argmin}} \\left[\\sum_{i = 1}^{N} |y_i-\\theta^T \\vec x_i| \\right]\n",
    "$$\n",
    "Таким образом, функция потерь (т.е. функция, которая должна быть минимизирована в процессе обучения модели), имеет вид:\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{i = 1}^{N} |y_i-\\theta^T \\vec x_i|\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
